{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPX5yyzODKiC/weOnGs2Mh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zh1212121/NLP-Assn-2/blob/main/Assignment_2_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gd3j_R1L9A3",
        "outputId": "2550fa82-db79-4b7e-a499-6869d8ce04e9"
      },
      "source": [
        "!git clone https://github.com/zh1212121/NLP-Assn-2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Assn-2'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 30 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS7iNWbN131e"
      },
      "source": [
        "##1. Import libraries and check version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "j-G4rQD5ASeh",
        "outputId": "42e94c62-dac2-45eb-d5d7-5bfe0c1596eb"
      },
      "source": [
        "!pip install scikit-learn==0.21\n",
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.19.0\n",
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21 in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.19.0)\n",
            "Uninstalling numpy-1.19.0:\n",
            "  Successfully uninstalled numpy-1.19.0\n",
            "Collecting numpy==1.19.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a8/31/e2c3eda7afe7dab08e1f24767b8e38ff2f30dc82bd74aa3a5324c550366a/numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJyumfBA029"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import sklearn as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from sklearn import model_selection, metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdqTgesXvLuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJlT2_HXtWc4",
        "outputId": "ebc81f7c-dda1-46da-c06d-8b46ad197eab"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX9-x_t5yCXG"
      },
      "source": [
        "seed = 1234"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvAFrgcBPfsK",
        "outputId": "b9dc11a5-0a49-4d2b-b182-404b43a8b249"
      },
      "source": [
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(sk.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.0\n",
            "1.1.5\n",
            "0.21.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqXPCuHXBFVI"
      },
      "source": [
        "##2. Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCxR7bzfyZ69"
      },
      "source": [
        "#input the test dataset path here\n",
        "path_exam = \"https://raw.githubusercontent.com/zh1212121/NLP-Assn-2/main/Test-format.csv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRrPcb1YdZiq"
      },
      "source": [
        "#import given datasets\n",
        "exam_raw = pd.read_csv(path_exam, header = None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BmYwQTUAUJlC",
        "outputId": "01ab1852-750d-4075-8d72-7c0fe437ae20"
      },
      "source": [
        "exam_raw.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>review 1 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>review 2 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>review 3 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>review 4 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review 5 x y z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "0  review 1 x y z\n",
              "1  review 2 x y z\n",
              "2  review 3 x y z\n",
              "3  review 4 x y z\n",
              "4  review 5 x y z"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYB4SgRvKl6e"
      },
      "source": [
        "## 3. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKj8ahhHvxXr"
      },
      "source": [
        "#change text to lower case\n",
        "def convert_to_lower(text):\n",
        "  return text.lower()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwNkG9YvvxXs"
      },
      "source": [
        "#remove <br />\n",
        "def remove_newline(text):\n",
        "  return re.sub('<br />', '', text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDlJ4Cj1vxXs"
      },
      "source": [
        "#remove http:// links\n",
        "def remove_link(text):\n",
        "  return re.sub(r'http[s]?://\\S+\\b', '', text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHfSllqrvxXs"
      },
      "source": [
        "#decontraction\n",
        "def decontract(text):\n",
        "  text = re.sub(r\"won\\'t\", \" will not\", text)\n",
        "  text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
        "  text = re.sub(r\"can\\'t\", \" can not\", text)\n",
        "  text = re.sub(r\"don\\'t\", \" do not\", text)\n",
        "    \n",
        "  text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
        "  text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
        "  text = re.sub(r\"let\\'s\", \" let us\", text)\n",
        "  text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
        "  text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
        "  text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
        "  text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
        "  text = re.sub(r\"y\\'all\", \" you all\", text)\n",
        "\n",
        "  text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "  text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\"\\'d've\", \" would have\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
        "  text = re.sub(r\"\\'t\", \" not\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'m\", \" am\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  return text\n",
        "\n",
        "#reference:\n",
        "#https://www.kaggle.com/faressayah/sentiment-model-with-tensorflow-transformers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1rSpuwKvxXs",
        "outputId": "22d09fc9-93f9-4c22-f65a-74e342e0795d"
      },
      "source": [
        "#remove punctuation\n",
        "print(string.punctuation)\n",
        "\n",
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMTjFAmlvxXt"
      },
      "source": [
        "#remove special characters & numbers \n",
        "def remove_special(text, remove_punc = True, remove_digits=True):\n",
        "  if remove_punc:\n",
        "    if remove_digits:\n",
        "      pattern=r'[^a-zA-z\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "    else:\n",
        "      pattern=r'[^a-zA-z0-9\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "  else:\n",
        "    if remove_digits:\n",
        "      pattern=r'[^a-zA-z\\!\\\"#$%&\\'()*+,-.//:;<=>\\?@[\\]^_`{|}~\\s'\n",
        "      text=re.sub(pattern,'',text)\n",
        "    else:\n",
        "      pattern=r'[^a-zA-z0-9\\!\\\"#$%&\\'()*+,-.//:;<=>\\?@[\\]^_`{|}~\\s'\n",
        "      text=re.sub(pattern,'',text)\n",
        "  return text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ajwyOIsvxXt",
        "outputId": "03e3c6cf-e45c-47c2-e9bc-8cda195107df"
      },
      "source": [
        "#view stopword list\n",
        "stop = stopwords.words('english')\n",
        "print(stop)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ8q4oiTvxXt",
        "outputId": "06716a42-7b1b-4739-ed7f-4743a47fbc79"
      },
      "source": [
        "#define my own stopword list to exclude those stopwards that could change meaning of a sentence, eg. can't, doesn't\n",
        "stopword_list = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \n",
        "                 \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
        "                 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', \n",
        "                 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", \n",
        "                 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', \n",
        "                 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', \n",
        "                 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', \n",
        "                 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', \n",
        "                 'up', 'down', 'in', 'out', 'on', 'off', 'further', 'then', 'here', 'there', 'when', 'where', \n",
        "                 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more','other', 'some', 'such', 'own', \n",
        "                 'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'now', 'd', 'll', 'm', 'o', \n",
        "                 're', 've', 'y', ]\n",
        "print(stopword_list)\n",
        "\n",
        "def remove_stopword(text):\n",
        "  result = ' '.join([i for i in text.split() if not i in stopword_list])\n",
        "  return result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'further', 'then', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'other', 'some', 'such', 'own', 'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD6JasVQvxXt"
      },
      "source": [
        "#Lemmatization\n",
        "def lemmatize(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = word_tokenize(text)\n",
        "  result = ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
        "  return result"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R90r13FHvxXt"
      },
      "source": [
        "#remove single character as it generally has less meaning\n",
        "def remove_single_char(text):\n",
        "  return re.sub(r'\\b\\w\\b', '', text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wPEyGELvxXt"
      },
      "source": [
        "#reduce multiple whitespaces to single space\n",
        "def reduce_space(text):\n",
        "  return re.sub(r'\\s+', ' ', text).strip()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egFTVNd6vxXu"
      },
      "source": [
        "def clean_text(text, remove_punc = False, remove_digits = False):\n",
        "  text = convert_to_lower(text)\n",
        "#  print(text)\n",
        "  text = remove_newline(text)\n",
        "#  print(text)\n",
        "  text = remove_link(text)\n",
        "#  print(text)\n",
        "  text = decontract(text)\n",
        "#  print(text)\n",
        "  text = remove_special(text, remove_punc, remove_digits)\n",
        "#  print(text)\n",
        "  text = remove_stopword(text)\n",
        "#  print(text)  \n",
        "#  text = lemmatize(text)\n",
        "#  print(text)\n",
        "  text = remove_single_char(text)\n",
        "#  print(text)\n",
        "  text = reduce_space(text)\n",
        "#  print(text)\n",
        "\n",
        "  return text"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmOaCUwcvxXu"
      },
      "source": [
        "punc = True\n",
        "dig = False"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQvGa4TsBdgS"
      },
      "source": [
        "exam_raw['Clean_text'] = exam_raw[:][0].apply(clean_text, remove_punc = punc, remove_digits = dig)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XWLfmYbXL4O8",
        "outputId": "5de7228a-ad7d-415d-e881-b32d76e53179"
      },
      "source": [
        "exam_raw.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>review 1 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>review 2 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>review 3 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>review 4 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review 5 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0 Clean_text\n",
              "0  review 1 x y z     review\n",
              "1  review 2 x y z     review\n",
              "2  review 3 x y z     review\n",
              "3  review 4 x y z     review\n",
              "4  review 5 x y z     review"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gT12nSmwlNI"
      },
      "source": [
        "x_exam = exam_raw['Clean_text']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wnKFbSBg0Z"
      },
      "source": [
        "##4. Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osHjFvzIF-0o",
        "outputId": "6ce22f4f-d063-491c-c17a-555b4414c747"
      },
      "source": [
        "filename_vec = '/content/NLP-Assn-2/vectorizer.pickle'\n",
        "pickle.load(open(filename_vec, 'rb'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.8, max_features=None,\n",
              "                min_df=5, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_J8j4oHBdZI"
      },
      "source": [
        "filename = '/content/NLP-Assn-2/model.sav'\n",
        "model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPPwPVDxQ0RP"
      },
      "source": [
        "##5. Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73yu0xOKfVR"
      },
      "source": [
        "y_pred = model.predict(x_exam)\n",
        "#print(y_pred)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi8gXwejLUzc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7bdeeb8b-145b-49fb-fd4b-3c170013480f"
      },
      "source": [
        "#output to df\n",
        "output = pd.DataFrame({'Text': x_exam, 'Pred_Label': y_pred})\n",
        "output.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Pred_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>review</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>review</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>review</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>review</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Text  Pred_Label\n",
              "0  review           0\n",
              "1  review           0\n",
              "2  review           0\n",
              "3  review           0\n",
              "4  review           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3f2ZEvAy-Ah"
      },
      "source": [
        "#Download the Predicted result\n",
        "output.to_csv('Output_ZhengWanyu.csv')\n",
        "files.download('Output_ZhengWanyu.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7cK5_jozd_h"
      },
      "source": [
        "#Evaluation - **Require User Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--QBDcvjzG2j"
      },
      "source": [
        "#define the ground labels as y_exam\n",
        "y_exam = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j601MaND1ZYX"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtrT9bFWLMKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "f9dc8ba8-7719-4c3f-a1b5-935884f494f9"
      },
      "source": [
        "print('classification report on test data is shown below:')\n",
        "report = classification_report(y_exam, y_pred)\n",
        "print(report)\n",
        "\n",
        "f1_score = sk.metrics.f1_score(y_exam, y_pred)\n",
        "print('f1 score of the model on test data is:', round(f1_score, 2))\n",
        "print(f1_score)\n",
        "\n",
        "accuracy = sk.metrics.accuracy_score(y_exam, y_pred)\n",
        "print('accuracy of the model on test data is:', round(accuracy,2))\n",
        "print(accuracy)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classification report on test data is shown below:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-33104cf3f4ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classification report on test data is shown below:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_exam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_exam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_exam' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehggv7-lQ1dZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}