{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5b6idoaKc1RSmRNTbxksg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zh1212121/NLP-Assn-2/blob/main/Assignment_2_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gd3j_R1L9A3",
        "outputId": "158913a2-cb59-4433-b919-01c8cb06287b"
      },
      "source": [
        "!git clone https://github.com/zh1212121/NLP-Assn-2.git"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'NLP-Assn-2' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "j-G4rQD5ASeh",
        "outputId": "44de7adc-f4fb-4f58-b2c1-f2051617deb7"
      },
      "source": [
        "#!pip install Torch==1.7.0\n",
        "#!pip install tensorflow==2.3.0\n",
        "#!pip install transformers==4.5.0\n",
        "!pip install scikit-learn==0.21\n",
        "#!pip install keras==2.3.1\n",
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.19.0\n",
        "!pip install nltk"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21 in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.19.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21) (1.0.1)\n",
            "Uninstalling numpy-1.19.0:\n",
            "  Successfully uninstalled numpy-1.19.0\n",
            "Collecting numpy==1.19.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a8/31/e2c3eda7afe7dab08e1f24767b8e38ff2f30dc82bd74aa3a5324c550366a/numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJyumfBA029"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "#import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "#import transformers\n",
        "import sklearn as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from sklearn import model_selection, metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE_4lc_PA3jX",
        "outputId": "b5a11db2-adee-408e-f04f-b99b9390e80b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWJSQOkkA73M"
      },
      "source": [
        "seed = 1234"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGCOwJ4WBBPd",
        "outputId": "45102a49-26fd-494e-ee62-dcf3059fba7b"
      },
      "source": [
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "#print(tf.__version__)\n",
        "#print(torch.__version__)\n",
        "#print(transformers.__version__)\n",
        "print(sk.__version__)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.0\n",
            "1.1.5\n",
            "0.21.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_t8_27BBtq"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqXPCuHXBFVI"
      },
      "source": [
        "##import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRrPcb1YdZiq"
      },
      "source": [
        "#import given datasets\n",
        "path_exam = \"https://raw.githubusercontent.com/zh1212121/NLP-Assn-2/main/Test-format.csv\"\n",
        "exam_raw = pd.read_csv(path_exam, header = None)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BmYwQTUAUJlC",
        "outputId": "8655febb-3532-4e42-d30e-81f91ae09967"
      },
      "source": [
        "exam_raw.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>review 1 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>review 2 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>review 3 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>review 4 x y z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review 5 x y z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "0  review 1 x y z\n",
              "1  review 2 x y z\n",
              "2  review 3 x y z\n",
              "3  review 4 x y z\n",
              "4  review 5 x y z"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYB4SgRvKl6e"
      },
      "source": [
        "## data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ujOKhCBdmG"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YQ1Y6FdqP71"
      },
      "source": [
        "lowercase<br />\n",
        "remove $<br />$<br />\n",
        "remove url (http://)<br />\n",
        "remove punctuation<br />\n",
        "remove non-char words/special char<br />\n",
        "\n",
        "remove stopwords (pending testing)<br />\n",
        "lemmatization (pending testing)<br />\n",
        "remove single char\n",
        "reduce multiple whitespaces\n",
        "normalize?\n",
        "\n",
        "tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSSwh5tlce0Z"
      },
      "source": [
        "#change text to lower case\n",
        "def convert_to_lower(text):\n",
        "  return text.lower()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2tO_t9fwgyg"
      },
      "source": [
        "#remove <br />\n",
        "def remove_newline(text):\n",
        "  return re.sub('<br />', '', text)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5yXr80FzGDN"
      },
      "source": [
        "#remove http:// links\n",
        "def remove_link(text):\n",
        "  return re.sub(r'http[s]?://\\S+\\b', '', text)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08P-998WhpPi"
      },
      "source": [
        "#decontraction\n",
        "def decontract(text):\n",
        "  text = re.sub(r\"won\\'t\", \" will not\", text)\n",
        "  text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
        "  text = re.sub(r\"can\\'t\", \" can not\", text)\n",
        "  text = re.sub(r\"don\\'t\", \" do not\", text)\n",
        "    \n",
        "  text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
        "  text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
        "  text = re.sub(r\"let\\'s\", \" let us\", text)\n",
        "  text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
        "  text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
        "  text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
        "  text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
        "  text = re.sub(r\"y\\'all\", \" you all\", text)\n",
        "\n",
        "  text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "  text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\"\\'d've\", \" would have\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
        "  text = re.sub(r\"\\'t\", \" not\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'m\", \" am\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  return text\n",
        "\n",
        "#reference:\n",
        "#https://www.kaggle.com/faressayah/sentiment-model-with-tensorflow-transformers"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "UP7Ax4F_h6DT",
        "outputId": "d7f3c5ae-4f08-4aee-fdc1-8cb91480097d"
      },
      "source": [
        "sample = \"I didn't expect to like this film as much as I did. I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time. It didn't look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It's about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film's crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it's a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I didn't think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.\"\n",
        "\n",
        "decontract(sample)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I did not expect to like this film as much as I did. I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time. It did not look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It is about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film is crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it is a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I did not think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_70hr8HM2kci",
        "outputId": "f45a42d1-90b0-4a69-97bd-866c1d73154f"
      },
      "source": [
        "#remove punctuation\n",
        "print(string.punctuation)\n",
        "\n",
        "punctuation_defined = '\\\"#%\\'()*+-//<=>@[\\]^_`{|}'\n",
        "print(punctuation_defined)\n",
        "\n",
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('', '', punctuation_defined))\n",
        "  #  return text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\"#%'()*+-//<=>@[\\]^_`{|}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGWNH0eD5xpo"
      },
      "source": [
        "#remove special characters & numbers\n",
        "def remove_special(text, remove_punc = True, remove_digits=True):\n",
        "  if remove_punc:\n",
        "    if remove_digits:\n",
        "      pattern=r'[^a-zA-z\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "    else:\n",
        "      pattern=r'[^a-zA-z0-9\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "  else:\n",
        "    if remove_digits:\n",
        "      pattern=r'[^a-zA-z\\\"#%\\'()*+-//<=>@[\\]^_`{|}\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "    else:\n",
        "      pattern=r'[^a-zA-z0-9\\\"#%\\'()*+-//<=>@[\\]^_`{|}\\s]'\n",
        "      text=re.sub(pattern,'',text)\n",
        "  return text"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1FrJBfqufez",
        "outputId": "a7b5f32b-ed68-4855-c10a-941bd3f455e2"
      },
      "source": [
        "sample = \"I didn't expect to like this film as much as I did. I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time. It didn't look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It's about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film's crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it's a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I didn't think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.\"\n",
        "\n",
        "sample1 = remove_special(sample, True, True)\n",
        "sample2 = remove_special(sample,False,True)\n",
        "sample3 = remove_special(sample,True,False)\n",
        "sample4 = remove_special(sample, False, False)\n",
        "print(sample1)\n",
        "print(sample2)\n",
        "print(sample3)\n",
        "print(sample4)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I didnt expect to like this film as much as I did I got it simply because I saw it on the list of Top  Most Controversial Films of All Time It didnt look particularly great I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memorybr br Its about a twentyyearold woman wants to know everything She stores every bit of information she collects in an enormous archive She experiments with experience in sex political activism and human relationships Meanwhile films crew is shown making the film and we view their reactions to the story and each other Nudity explicit sex and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed The film is a narrative yet its a documentary that shows us the behindthe scenes world of the filmmakers during the narrative the fourth wall being broken This film is the most direct possible way of making a movie I have ever seen The movie predominantly works as a time capsule of s psychedelic goingson freedomfighting and sexual liberation I like to think of it as much more than thatbr br I didnt think I would want to waste my time with the blue version of this movie but I actually really do This film is a buried treasure Give it a try\n",
            "I didn't expect to like this film as much as I did. I got it simply because I saw it on the list of Top  Most Controversial Films of All Time. It didn't look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It's about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film's crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it's a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I didn't think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.\n",
            "I didnt expect to like this film as much as I did I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time It didnt look particularly great I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memorybr br Its about a twentyyearold woman wants to know everything She stores every bit of information she collects in an enormous archive She experiments with experience in sex political activism and human relationships Meanwhile films crew is shown making the film and we view their reactions to the story and each other Nudity explicit sex and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed The film is a narrative yet its a documentary that shows us the behindthe scenes world of the filmmakers during the narrative the fourth wall being broken This film is the most direct possible way of making a movie I have ever seen The movie predominantly works as a time capsule of 1960s psychedelic goingson freedomfighting and sexual liberation I like to think of it as much more than thatbr br I didnt think I would want to waste my time with the blue version of this movie but I actually really do This film is a buried treasure Give it a try\n",
            "I didn't expect to like this film as much as I did. I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time. It didn't look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It's about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film's crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it's a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I didn't think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ3v6gmSxFD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1661bb0f-5432-45dc-f60e-50217d0a29b6"
      },
      "source": [
        "#view stopword list\n",
        "stop = stopwords.words('english')\n",
        "print(stop)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf7RT-aj5xeG",
        "outputId": "e779d59c-97d0-4d43-b694-3994dab8efdc"
      },
      "source": [
        "#define my own stopword list to exclude those stopwards that could change meaning of a sentence, eg. can't, doesn't\n",
        "stopword_list = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \n",
        "                 \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
        "                 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', \n",
        "                 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", \n",
        "                 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', \n",
        "                 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', \n",
        "                 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', \n",
        "                 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', \n",
        "                 'up', 'down', 'in', 'out', 'on', 'off', 'further', 'then', 'here', 'there', 'when', 'where', \n",
        "                 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more','other', 'some', 'such', 'own', \n",
        "                 'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'now', 'd', 'll', 'm', 'o', \n",
        "                 're', 've', 'y', ]\n",
        "print(stopword_list)\n",
        "\n",
        "def remove_stopword(text):\n",
        "  result = ' '.join([i for i in text.split() if not i in stopword_list])\n",
        "  return result"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'further', 'then', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'other', 'some', 'such', 'own', 'same', 'so', 'than', 'too', 's', 't', 'can', 'will', 'just', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFg4I9kbEnek"
      },
      "source": [
        "#Lemmatization\n",
        "def lemmatize(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = word_tokenize(text)\n",
        "  result = ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
        "  return result"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK4IevI2mnmQ"
      },
      "source": [
        "#remove single character as it generally has less meaning\n",
        "def remove_single_char(text):\n",
        "  return re.sub(r'\\b\\w\\b', '', text)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x26flgluBlK"
      },
      "source": [
        "#reduce multiple whitespaces to single space\n",
        "def reduce_space(text):\n",
        "  return re.sub(r'\\s+', ' ', text).strip()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2iSoJ0Zmu4y",
        "outputId": "5b4643c9-3fb3-4744-c126-c6a3dc4a078e"
      },
      "source": [
        "sample = \"I didn't expect to like this film as much as I did. I got it simply because I saw it on the list of Top 25 Most Controversial Films of All Time. It didn't look particularly great. I was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It's about a twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film's crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is a narrative yet it's a documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making a movie I have ever seen. The movie predominantly works as a time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. I like to think of it as much more than that.<br /><br />I didn't think I would want to waste my time with the blue version of this movie, but I actually really do. This film is a buried treasure. Give it a try.\"\n",
        "\n",
        "sample = remove_single_char(sample)\n",
        "\n",
        "print(sample)\n",
        "print(reduce_space(sample))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " didn' expect to like this film as much as  did.  got it simply because  saw it on the list of Top 25 Most Controversial Films of All Time. It didn' look particularly great.  was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It' about  twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film' crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is  narrative yet it'  documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making  movie  have ever seen. The movie predominantly works as  time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation.  like to think of it as much more than that.<br /><br /> didn' think  would want to waste my time with the blue version of this movie, but  actually really do. This film is  buried treasure. Give it  try.\n",
            "didn' expect to like this film as much as did. got it simply because saw it on the list of Top 25 Most Controversial Films of All Time. It didn' look particularly great. was pleasantly surprised to find that it was one of the most cleverly composed films of recent memory.<br /><br />It' about twenty-year-old woman wants to know everything. She stores every bit of information she collects in an enormous archive. She experiments with experience in sex, political activism, and human relationships. Meanwhile, film' crew is shown making the film and we view their reactions to the story and each other. Nudity, explicit sex, and controversial politics kept this film from being shown in the US while its seizure by Customs was appealed. The film is narrative yet it' documentary that shows us the behind-the- scenes world of the filmmakers during the narrative, the fourth wall being broken. This film is the most direct possible way of making movie have ever seen. The movie predominantly works as time capsule of 1960s psychedelic goings-on, freedom-fighting and sexual liberation. like to think of it as much more than that.<br /><br /> didn' think would want to waste my time with the blue version of this movie, but actually really do. This film is buried treasure. Give it try.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSR7Rri5xTo"
      },
      "source": [
        "def clean_text(text, remove_punc = False, remove_digits = False):\n",
        "  text = convert_to_lower(text)\n",
        "#  print(text)\n",
        "  text = remove_newline(text)\n",
        "#  print(text)\n",
        "  text = remove_link(text)\n",
        "#  print(text)\n",
        "  text = decontract(text)\n",
        "#  print(text)\n",
        "  text = remove_special(text, remove_punc, remove_digits)\n",
        "#  print(text)\n",
        "  text = remove_stopword(text)\n",
        "#  print(text)  \n",
        "#  text = lemmatize(text)\n",
        "#  print(text)\n",
        "  text = remove_single_char(text)\n",
        "#  print(text)\n",
        "  text = reduce_space(text)\n",
        "#  print(text)\n",
        "\n",
        "  return text"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC2LposcwM0y"
      },
      "source": [
        "punc = False\n",
        "dig = False"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQvGa4TsBdgS"
      },
      "source": [
        "exam_raw['Clean_text'] = exam_raw[:][0].apply(clean_text, remove_punc = punc, remove_digits = dig)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XWLfmYbXL4O8",
        "outputId": "c94df841-8cc8-4c4a-fdcd-277620cb599d"
      },
      "source": [
        "exam_raw.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>review 1 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>review 2 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>review 3 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>review 4 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review 5 x y z</td>\n",
              "      <td>review</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0 Clean_text\n",
              "0  review 1 x y z     review\n",
              "1  review 2 x y z     review\n",
              "2  review 3 x y z     review\n",
              "3  review 4 x y z     review\n",
              "4  review 5 x y z     review"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wnKFbSBg0Z"
      },
      "source": [
        "##load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osHjFvzIF-0o",
        "outputId": "0108ab9d-24a6-4887-bb6a-35bab85c3329"
      },
      "source": [
        "filename_vec = '/content/NLP-Assn-2/vectorizer.pickle'\n",
        "pickle.load(open(filename_vec, 'rb'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Assn-2'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_J8j4oHBdZI"
      },
      "source": [
        "filename = '/content/NLP-Assn-2/model_1.sav'\n",
        "model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KzfQSISBdRT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6PCDc11KfnB"
      },
      "source": [
        "##predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "6I8Ptjb1K37y",
        "outputId": "c4f38231-36b0-4272-9f28-14de45d3ce62"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 5,\n",
        "                             max_df = 0.8,\n",
        "                             sublinear_tf = True,\n",
        "                             use_idf = True)\n",
        "exam_vectors = vectorizer.transform(exam_raw['Clean_text'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-ecbcca125f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0msublinear_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              use_idf = True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexam_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexam_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73yu0xOKfVR"
      },
      "source": [
        "pred = model.predict(exam_vectors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24aC9DKILJ2A"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi8gXwejLUzc"
      },
      "source": [
        "#output to df\n",
        "exam['Pred_label'] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLa5FvirLUqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtrT9bFWLMKI"
      },
      "source": [
        "f1_score = sk.metrics.f1_score(list(test['Label']), prediction_linear)\n",
        "print(round(f1_score, 2))\n",
        "print(f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}